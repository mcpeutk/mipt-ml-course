{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv')\ntest = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')\nsample_submission = pd.read_csv('/kaggle/input/home-credit-default-risk/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Empty fields fulfillment\n\ntrain.fillna(method = \"ffill\", inplace = True)\ntest.fillna(method = \"ffill\", inplace = True)\n\n# NaN's removement\n\ntrain = train.dropna()\ntrain = train.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical features encoding\n\ncategorical_fields = []\n\nfor col, col_type in dict(train.dtypes).items():\n    if col_type == object:\n        categorical_fields.append(col)\n        \nprint(categorical_fields)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in categorical_fields:\n    train_encoder = preprocessing.LabelEncoder()\n    train[col] = train_encoder.fit_transform(train[col])\n    \n    test_encoder = preprocessing.LabelEncoder()\n    test[col] = test_encoder.fit_transform(test[col].astype(str))\n    \ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalization\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler_x = MinMaxScaler()\nscaler_y = MinMaxScaler()\n\ntrain[train.columns[:-1]] = scaler_x.fit_transform(train.iloc[:, :-1])\ntrain[['TARGET']] = scaler_y.fit_transform(train[['TARGET']])\n\ntest[test.columns] = scaler_x.fit_transform(test)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features selection\n\n# RFE\n\nmodel = LogisticRegression(max_iter = 1000)\n\n# help(RFE)\n\nrfe = RFE(model, n_features_to_select = 10, step = 10, verbose = 1)\n\ncolumns = list(train.columns)\ncolumns.remove('TARGET')\n\nfit = rfe.fit(train.loc[:, columns], train[\"TARGET\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_list = list(pd.Index(columns)[fit.support_])\n\nprint(features_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in features_list:\n    train[feature + '_LOG'] = np.log1p(train[feature])\n    test[feature + '_LOG'] =np.log1p(test[feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize= (8,8))\nplt.hist(train['AMT_CREDIT_LOG'], bins = 100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize= (8,8))\nplt.hist(train['AMT_ANNUITY_LOG'], bins = 100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_list = []\n\nkf = KFold(n_splits=5)\nkf.get_n_splits(train)\n\nmodel = LogisticRegression()\nfeatures = features_list[:1]\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n    \n    X_train, X_test = train.loc[train_index, features], train.loc[test_index, features ]\n    y_train, y_test = train.loc[train_index, 'TARGET'], train.loc[test_index, 'TARGET']\n\n    model.fit(X_train, y_train)\n    predict = model.predict_proba(X_test)[:,1]\n    roc_auc = roc_auc_score(y_test, predict)\n    roc_auc_list.append(roc_auc)\n    print(i, roc_auc)\n    \nprint(\"mean rmse for 5-fold: {}\".format(str(np.mean(roc_auc_list))))\nprint(\"std roc_auc for 5-fold: {}\".format(str(np.std(roc_auc_list))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train[features], train['TARGET'])\n\nsample_submission['TARGET'] = model.predict_proba(test[features]) [:,1]\n\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_list = []\n\nkf = KFold(n_splits=5)\nkf.get_n_splits(train)\n\nmodel = LogisticRegression()\nfeatures = features_list[:2]\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n    \n    X_train, X_test = train.loc[train_index, features], train.loc[test_index, features ]\n    y_train, y_test = train.loc[train_index, 'TARGET'], train.loc[test_index, 'TARGET']\n\n    model.fit(X_train, y_train)\n    predict = model.predict_proba(X_test)[:,1]\n    roc_auc = roc_auc_score(y_test, predict)\n    roc_auc_list.append(roc_auc)\n    print(i, roc_auc)\n    \nprint(\"mean rmse for 5-fold: {}\".format(str(np.mean(roc_auc_list))))\nprint(\"std roc_auc for 5-fold: {}\".format(str(np.std(roc_auc_list))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train[features], train['TARGET'])\n\nsample_submission['TARGET'] = model.predict_proba(test[features]) [:,1]\n\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_list = []\n\nkf = KFold(n_splits=5)\nkf.get_n_splits(train)\n\nmodel = LogisticRegression()\nfeatures = features_list[:4]\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n    \n    X_train, X_test = train.loc[train_index, features], train.loc[test_index, features ]\n    y_train, y_test = train.loc[train_index, 'TARGET'], train.loc[test_index, 'TARGET']\n\n    model.fit(X_train, y_train)\n    predict = model.predict_proba(X_test)[:,1]\n    roc_auc = roc_auc_score(y_test, predict)\n    roc_auc_list.append(roc_auc)\n    print(i, roc_auc)\n    \nprint(\"mean rmse for 5-fold: {}\".format(str(np.mean(roc_auc_list))))\nprint(\"std roc_auc for 5-fold: {}\".format(str(np.std(roc_auc_list))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train[features], train['TARGET'])\n\nsample_submission['TARGET'] = model.predict_proba(test[features]) [:,1]\n\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_list = []\n\nkf = KFold(n_splits=5)\nkf.get_n_splits(train)\n\nmodel = LogisticRegression()\nfeatures = features_list[:6]\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n    \n    X_train, X_test = train.loc[train_index, features], train.loc[test_index, features ]\n    y_train, y_test = train.loc[train_index, 'TARGET'], train.loc[test_index, 'TARGET']\n\n    model.fit(X_train, y_train)\n    predict = model.predict_proba(X_test)[:,1]\n    roc_auc = roc_auc_score(y_test, predict)\n    roc_auc_list.append(roc_auc)\n    print(i, roc_auc)\n    \nprint(\"mean rmse for 5-fold: {}\".format(str(np.mean(roc_auc_list))))\nprint(\"std roc_auc for 5-fold: {}\".format(str(np.std(roc_auc_list))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train[features], train['TARGET'])\n\nsample_submission['TARGET'] = model.predict_proba(test[features]) [:,1]\n\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_list = []\n\nkf = KFold(n_splits=5)\nkf.get_n_splits(train)\n\nmodel = LogisticRegression(max_iter = 1000)\nfeatures = features_list[:8]\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n    \n    X_train, X_test = train.loc[train_index, features], train.loc[test_index, features ]\n    y_train, y_test = train.loc[train_index, 'TARGET'], train.loc[test_index, 'TARGET']\n\n    model.fit(X_train, y_train)\n    predict = model.predict_proba(X_test)[:,1]\n    roc_auc = roc_auc_score(y_test, predict)\n    roc_auc_list.append(roc_auc)\n    print(i, roc_auc)\n    \nprint(\"mean rmse for 5-fold: {}\".format(str(np.mean(roc_auc_list))))\nprint(\"std roc_auc for 5-fold: {}\".format(str(np.std(roc_auc_list))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train[features], train['TARGET'])\n\nsample_submission['TARGET'] = model.predict_proba(test[features]) [:,1]\n\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_list = []\n\nkf = KFold(n_splits=5)\nkf.get_n_splits(train)\n\nmodel = LogisticRegression(max_iter = 1000)\nfeatures = features_list\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n    \n    X_train, X_test = train.loc[train_index, features], train.loc[test_index, features ]\n    y_train, y_test = train.loc[train_index, 'TARGET'], train.loc[test_index, 'TARGET']\n\n    model.fit(X_train, y_train)\n    predict = model.predict_proba(X_test)[:,1]\n    roc_auc = roc_auc_score(y_test, predict)\n    roc_auc_list.append(roc_auc)\n    print(i, roc_auc)\n    \nprint(\"mean rmse for 5-fold: {}\".format(str(np.mean(roc_auc_list))))\nprint(\"std roc_auc for 5-fold: {}\".format(str(np.std(roc_auc_list))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train[features], train['TARGET'])\n\nsample_submission['TARGET'] = model.predict_proba(test[features]) [:,1]\n\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dependence of cross-validation and leaderboard metric\n\ncross_validation_rates = [0.51859, 0.53020, 0.59376, 0.67591, 0.71215, 0.71230]\nleaderboard_rates = [0.51045, 0.53447, 0.59210, 0.65682, 0.70142, 0.70151]\n\nmetrics = np.arange(0.0, 1.0, 0.01)\n\nplt.plot(leaderboard_rates, cross_validation_rates)\nplt.ylabel('RMSE', fontsize=18)\nplt.xlabel('Leaderboard', fontsize=18)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}